{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example\n",
    "\n",
    "Original notebook by Alexander Held, edited for the MadMiner repository by Johann Brehmer, Irina Espejo, Felix Kling, and Kyle Cranmer 2018-2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use a simple toy example to demonstrate the machine learning and inference algorithms in MadMiner. This allows us to skip many of the more technical steps, and there's no dependency on MadGraph, Pythia, or Delphes.\n",
    "\n",
    "What this tutorial does not do, is explaining the inference methods. To understand what's happening, please have a look at [\"Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00013), which will explain the basic idea in just a few pages. If you really want to get down to the dirty details, [\"A Guide to Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00020) has you covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from madminer.ml import ParameterizedRatioEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MadMiner uses the Python `logging` module to provide additional information and debugging output. You can choose how much of this output you want to see by switching the level in the following lines to `logging.DEBUG` or `logging.WARNING`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MadMiner output\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)-5.5s %(name)-20.20s %(levelname)-7.7s %(message)s\",\n",
    "    datefmt=\"%H:%M\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "# Output of all other modules (e.g. matplotlib)\n",
    "for key in logging.Logger.manager.loggerDict:\n",
    "    if \"madminer\" not in key:\n",
    "        logging.getLogger(key).setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A toy simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simulator depends on just one parameter `theta` and produces one-dimensional observables `x`. It is characterized by one latent variable `z`. \"Running\" the simulator consists of two steps:\n",
    "- \"Hard process\": a value of `z` is drawn from a normal distribution, where the mean depends on `theta`. \n",
    "- \"Detector\": a value for `x` is drawn from a normal distribution with mean equal to `z`. There is no explicit dependence on `theta`.\n",
    "\n",
    "As in the particle physics case, we assume that we can calculate the joint likelihood ratio `r(x, z | theta0, theta1)` as well as the joint score `t(x, z | theta)`, which depend explicitly on `z` (and where the \"detector\" part cancels).\n",
    "\n",
    "Here are some general settings (feel free to play with them): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_std = 2.0\n",
    "x_std = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function runs the simulator for a value of `theta` and calculates the joint likelihood ratio between `theta0` and `theta1` as well as the joint score at `theta_score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(theta, theta0=None, theta1=None, theta_score=None, npoints=None):\n",
    "    # Draw latent variables z\n",
    "    z = np.random.normal(loc=theta, scale=z_std, size=npoints)\n",
    "\n",
    "    # Draw observables x\n",
    "    x = np.random.normal(loc=z, scale=x_std, size=None)\n",
    "\n",
    "    # Calculate joint likelihood ratio and joint score\n",
    "    if theta0 is not None and theta1 is not None:\n",
    "        r_xz = norm(loc=theta0, scale=z_std).pdf(z) / norm(loc=theta1, scale=z_std).pdf(z)\n",
    "    else:\n",
    "        r_xz = None\n",
    "\n",
    "    if theta_score is not None:\n",
    "        t_xz = (x - theta_score) / z_std**2\n",
    "    else:\n",
    "        t_xz = None\n",
    "\n",
    "    return x, r_xz, t_xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually the likelihood function `p(x|theta)` is intractable, but in this toy example it is just given by the convolution of two Gaussians, which is again a Gaussian. We will use this to validate the results later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood_ratio(x, theta0, theta1=0.0):\n",
    "    combined_std = (z_std**2 + x_std**2) ** 0.5\n",
    "    r_x = norm(loc=theta0, scale=combined_std).pdf(x) / norm(loc=theta1, scale=combined_std).pdf(x)\n",
    "    return r_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize that: we run the simulation and plot the probability distributions $p(x | \\theta_i)$. Additionally, we also plot the true log-likelihood ratio $\\log\\,r(x|\\theta_0,\\theta_1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Polygon.set() got an unexpected keyword argument 'normed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m fig\u001b[39m.\u001b[39mset_size_inches(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[1;32m      9\u001b[0m ax1\u001b[39m.\u001b[39mset_xlabel(\u001b[39m\"\u001b[39m\u001b[39m$x$\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m ax1\u001b[39m.\u001b[39;49mhist(x0, bins\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, \u001b[39mrange\u001b[39;49m\u001b[39m=\u001b[39;49m(\u001b[39m-\u001b[39;49m\u001b[39m10\u001b[39;49m, \u001b[39m10.0\u001b[39;49m), histtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mstep\u001b[39;49m\u001b[39m\"\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m$p(x | \u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mtheta_0)$\u001b[39;49m\u001b[39m\"\u001b[39;49m, normed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     11\u001b[0m ax1\u001b[39m.\u001b[39mhist(x1, bins\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, \u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m, \u001b[39m10.0\u001b[39m), histtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m$p(x | \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtheta_1)$\u001b[39m\u001b[39m\"\u001b[39m, normed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m ax1\u001b[39m.\u001b[39mset_ylabel(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m$p(x|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtheta)$\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/madminer/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1467\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/miniconda3/envs/madminer/lib/python3.10/site-packages/matplotlib/axes/_axes.py:7012\u001b[0m, in \u001b[0;36mAxes.hist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   7010\u001b[0m \u001b[39mif\u001b[39;00m patch:\n\u001b[1;32m   7011\u001b[0m     p \u001b[39m=\u001b[39m patch[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 7012\u001b[0m     p\u001b[39m.\u001b[39;49m_internal_update(kwargs)\n\u001b[1;32m   7013\u001b[0m     \u001b[39mif\u001b[39;00m lbl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   7014\u001b[0m         p\u001b[39m.\u001b[39mset_label(lbl)\n",
      "File \u001b[0;32m~/miniconda3/envs/madminer/lib/python3.10/site-packages/matplotlib/artist.py:1219\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_update\u001b[39m(\u001b[39mself\u001b[39m, kwargs):\n\u001b[1;32m   1213\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \n\u001b[1;32m   1217\u001b[0m \u001b[39m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_props(\n\u001b[1;32m   1220\u001b[0m         kwargs, \u001b[39m\"\u001b[39;49m\u001b[39m{cls.__name__}\u001b[39;49;00m\u001b[39m.set() got an unexpected keyword argument \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m   1221\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m{prop_name!r}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/madminer/lib/python3.10/site-packages/matplotlib/artist.py:1193\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1191\u001b[0m             func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mset_\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1192\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(func):\n\u001b[0;32m-> 1193\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   1194\u001b[0m                     errfmt\u001b[39m.\u001b[39mformat(\u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m), prop_name\u001b[39m=\u001b[39mk))\n\u001b[1;32m   1195\u001b[0m             ret\u001b[39m.\u001b[39mappend(func(v))\n\u001b[1;32m   1196\u001b[0m \u001b[39mif\u001b[39;00m ret:\n",
      "\u001b[0;31mAttributeError\u001b[0m: Polygon.set() got an unexpected keyword argument 'normed'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0, _, _ = simulate(-2, npoints=10000)\n",
    "x1, _, _ = simulate(2, npoints=10000)\n",
    "\n",
    "xr = np.linspace(-4.0, 4.0, 100)\n",
    "rx = np.log(calculate_likelihood_ratio(xr, -2, 2))\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "fig.set_size_inches(5, 5)\n",
    "ax1.set_xlabel(\"$x$\")\n",
    "ax1.hist(x0, bins=50, range=(-10, 10.0), histtype=\"step\", label=r\"$p(x | \\theta_0)$\", normed=True)\n",
    "ax1.hist(x1, bins=50, range=(-10, 10.0), histtype=\"step\", label=r\"$p(x | \\theta_1)$\", normed=True)\n",
    "ax1.set_ylabel(r\"$p(x|\\theta)$\")\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(xr, rx, color=\"black\", label=r\"$\\log\\,r(x|\\theta_0,\\theta_1)$\")\n",
    "ax2.set_ylabel(r\"$\\log\\,r(x|\\theta_0,\\theta_1)$\")\n",
    "ax2.legend(loc=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run the simulation and generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the parameter points we want to use for training: `theta0` is uniformly distributed while the reference model `theta1` is fixed at zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of parameter points to train\n",
    "n_param_points = 50000\n",
    "\n",
    "# numerator, uniform prior\n",
    "theta0 = np.random.uniform(low=-4.0, high=4.0, size=n_param_points)\n",
    "\n",
    "# denominator: fixed at 0\n",
    "theta1 = np.zeros(shape=n_param_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run the simulator (one sample per parameter point). Remember that `simulate(theta, theta0, theta1, theta_score)` generates data `x` following a theory with `theta` and then evaluates the joint likelihood ratio `r(x,z|theta0,theta1)` and the join score `t(x,z|theta_score)` for each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from theta0\n",
    "x_from_theta0, r_xz_from_theta0, t_xz_from_theta0 = simulate(theta0, theta0, theta1, theta0)\n",
    "\n",
    "# Sample from theta1\n",
    "x_from_theta1, r_xz_from_theta1, t_xz_from_theta1 = simulate(theta1, theta0, theta1, theta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine and reshape the results (nothing interesting happening here) and save everything to files, so that we can load it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results and reshape\n",
    "x_train = np.hstack((x_from_theta0, x_from_theta1)).reshape(-1, 1)\n",
    "r_xz_train = np.hstack((r_xz_from_theta0, r_xz_from_theta1)).reshape(-1, 1)\n",
    "t_xz_train = np.hstack((t_xz_from_theta0, t_xz_from_theta1)).reshape(-1, 1)\n",
    "y_train = np.hstack((np.zeros_like(x_from_theta0), np.ones_like(np.ones_like(x_from_theta1)))).reshape(-1, 1)\n",
    "theta0_train = np.hstack((theta0, theta0)).reshape(-1, 1)\n",
    "\n",
    "# Save to file\n",
    "np.save(\"data/theta0_train.npy\", theta0_train)\n",
    "np.save(\"data/x_train.npy\", x_train)\n",
    "np.save(\"data/y_train.npy\", y_train)\n",
    "np.save(\"data/r_xz_train.npy\", r_xz_train)\n",
    "np.save(\"data/t_xz_train.npy\", t_xz_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train two neural networks to estimate the likelihood ratio. For one we use the CARL method introduced in [\"Approximating Likelihood Ratios with Calibrated Discriminative Classifiers\"](https://arxiv.org/abs/1506.02169), for the other the new ALICES method introduced in [\"Likelihood-free inference with an improved cross-entropy estimator\"](https://arxiv.org/abs/1808.00973)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:33 madminer.ml          INFO    Starting training\n",
      "16:33 madminer.ml          INFO      Method:                 carl\n",
      "16:33 madminer.ml          INFO      Batch size:             128\n",
      "16:33 madminer.ml          INFO      Optimizer:              amsgrad\n",
      "16:33 madminer.ml          INFO      Epochs:                 20\n",
      "16:33 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:33 madminer.ml          INFO      Validation split:       0.25\n",
      "16:33 madminer.ml          INFO      Early stopping:         True\n",
      "16:33 madminer.ml          INFO      Scale inputs:           True\n",
      "16:33 madminer.ml          INFO      Scale parameters:       False\n",
      "16:33 madminer.ml          INFO      Shuffle labels          False\n",
      "16:33 madminer.ml          INFO      Samples:                all\n",
      "16:33 madminer.ml          INFO    Loading training data\n",
      "16:33 madminer.utils.vario INFO      Loading data/theta0_train.npy into RAM\n",
      "16:33 madminer.utils.vario INFO      Loading data/x_train.npy into RAM\n",
      "16:33 madminer.utils.vario INFO      Loading data/y_train.npy into RAM\n",
      "16:33 madminer.ml          INFO    Found 100000 samples with 1 parameters and 1 observables\n",
      "16:33 madminer.ml          INFO    Setting up input rescaling\n",
      "16:33 madminer.ml          INFO    Disabling parameter rescaling\n",
      "16:33 madminer.ml          INFO    Creating model\n",
      "16:33 madminer.ml          INFO    Training model\n",
      "16:33 madminer.utils.ml.tr INFO    Training on CPU with single precision\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   1: train loss  0.62682 (xe:  0.627)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58953 (xe:  0.590)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   2: train loss  0.59146 (xe:  0.591)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58761 (xe:  0.588)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   3: train loss  0.59012 (xe:  0.590)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58562 (xe:  0.586)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   4: train loss  0.58901 (xe:  0.589)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58655 (xe:  0.587)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   5: train loss  0.58821 (xe:  0.588)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58556 (xe:  0.586)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   6: train loss  0.58793 (xe:  0.588)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58511 (xe:  0.585)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   7: train loss  0.58754 (xe:  0.588)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58698 (xe:  0.587)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   8: train loss  0.58743 (xe:  0.587)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58478 (xe:  0.585)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch   9: train loss  0.58722 (xe:  0.587)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58428 (xe:  0.584)\n",
      "16:33 madminer.utils.ml.tr INFO    Epoch  10: train loss  0.58688 (xe:  0.587)\n",
      "16:33 madminer.utils.ml.tr INFO               val. loss   0.58436 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  11: train loss  0.58688 (xe:  0.587)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58562 (xe:  0.586)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  12: train loss  0.58681 (xe:  0.587)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58442 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  13: train loss  0.58671 (xe:  0.587)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58446 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  14: train loss  0.58657 (xe:  0.587)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58417 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  15: train loss  0.58662 (xe:  0.587)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58410 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  16: train loss  0.58647 (xe:  0.586)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58364 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  17: train loss  0.58641 (xe:  0.586)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58375 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  18: train loss  0.58637 (xe:  0.586)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58402 (xe:  0.584)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  19: train loss  0.58630 (xe:  0.586)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58343 (xe:  0.583)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch  20: train loss  0.58632 (xe:  0.586)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58342 (xe:  0.583)\n",
      "16:34 madminer.utils.ml.tr INFO    Early stopping did not improve performance\n",
      "16:34 madminer.utils.ml.tr INFO    Training time spend on:\n",
      "16:34 madminer.utils.ml.tr INFO                      initialize model:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                                   ALL:   0.03h\n",
      "16:34 madminer.utils.ml.tr INFO                            check data:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                          make dataset:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                       make dataloader:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                   initialize training:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                                set lr:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                   load training batch:   0.01h\n",
      "16:34 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                 training forward pass:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                   training sum losses:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                         opt: backward:   0.01h\n",
      "16:34 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                             opt: step:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                        optimizer step:   0.01h\n",
      "16:34 madminer.utils.ml.tr INFO                 load validation batch:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO               validation forward pass:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                        early stopping:   0.00h\n",
      "16:34 madminer.utils.ml.tr INFO                          report epoch:   0.00h\n",
      "16:34 madminer.ml          INFO    Saving model to models/carl\n"
     ]
    }
   ],
   "source": [
    "carl = ParameterizedRatioEstimator(n_hidden=(20, 20))\n",
    "\n",
    "carl.train(\n",
    "    method=\"carl\",\n",
    "    x=\"data/x_train.npy\",\n",
    "    y=\"data/y_train.npy\",\n",
    "    theta=\"data/theta0_train.npy\",\n",
    "    n_epochs=20,\n",
    ")\n",
    "\n",
    "carl.save(\"models/carl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:34 madminer.ml          INFO    Starting training\n",
      "16:34 madminer.ml          INFO      Method:                 alices\n",
      "16:34 madminer.ml          INFO      alpha:                  0.1\n",
      "16:34 madminer.ml          INFO      Batch size:             128\n",
      "16:34 madminer.ml          INFO      Optimizer:              amsgrad\n",
      "16:34 madminer.ml          INFO      Epochs:                 20\n",
      "16:34 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:34 madminer.ml          INFO      Validation split:       0.25\n",
      "16:34 madminer.ml          INFO      Early stopping:         True\n",
      "16:34 madminer.ml          INFO      Scale inputs:           True\n",
      "16:34 madminer.ml          INFO      Scale parameters:       False\n",
      "16:34 madminer.ml          INFO      Shuffle labels          False\n",
      "16:34 madminer.ml          INFO      Samples:                all\n",
      "16:34 madminer.ml          INFO    Loading training data\n",
      "16:34 madminer.utils.vario INFO      Loading data/theta0_train.npy into RAM\n",
      "16:34 madminer.utils.vario INFO      Loading data/x_train.npy into RAM\n",
      "16:34 madminer.utils.vario INFO      Loading data/y_train.npy into RAM\n",
      "16:34 madminer.utils.vario INFO      Loading data/r_xz_train.npy into RAM\n",
      "16:34 madminer.utils.vario INFO      Loading data/t_xz_train.npy into RAM\n",
      "16:34 madminer.ml          INFO    Found 100000 samples with 1 parameters and 1 observables\n",
      "16:34 madminer.ml          INFO    Setting up input rescaling\n",
      "16:34 madminer.ml          INFO    Disabling parameter rescaling\n",
      "16:34 madminer.ml          INFO    Creating model\n",
      "16:34 madminer.ml          INFO    Training model\n",
      "16:34 madminer.utils.ml.tr INFO    Training on CPU with single precision\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch   1: train loss  0.62208 (improved_xe:  0.614, mse_score:  0.077)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.59074 (improved_xe:  0.589, mse_score:  0.022)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch   2: train loss  0.58822 (improved_xe:  0.587, mse_score:  0.016)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58760 (improved_xe:  0.586, mse_score:  0.012)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch   3: train loss  0.58665 (improved_xe:  0.586, mse_score:  0.010)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58706 (improved_xe:  0.586, mse_score:  0.008)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch   4: train loss  0.58617 (improved_xe:  0.585, mse_score:  0.008)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58655 (improved_xe:  0.586, mse_score:  0.007)\n",
      "16:34 madminer.utils.ml.tr INFO    Epoch   5: train loss  0.58590 (improved_xe:  0.585, mse_score:  0.007)\n",
      "16:34 madminer.utils.ml.tr INFO               val. loss   0.58617 (improved_xe:  0.585, mse_score:  0.007)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   6: train loss  0.58579 (improved_xe:  0.585, mse_score:  0.006)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58636 (improved_xe:  0.586, mse_score:  0.006)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   7: train loss  0.58569 (improved_xe:  0.585, mse_score:  0.006)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58620 (improved_xe:  0.586, mse_score:  0.006)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   8: train loss  0.58563 (improved_xe:  0.585, mse_score:  0.006)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58586 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   9: train loss  0.58557 (improved_xe:  0.585, mse_score:  0.006)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58596 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  10: train loss  0.58554 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58608 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  11: train loss  0.58552 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58589 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  12: train loss  0.58551 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58608 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  13: train loss  0.58547 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58602 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  14: train loss  0.58546 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58606 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  15: train loss  0.58546 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58601 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  16: train loss  0.58543 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58607 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  17: train loss  0.58542 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58613 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  18: train loss  0.58542 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58594 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  19: train loss  0.58541 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58604 (improved_xe:  0.586, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch  20: train loss  0.58540 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58587 (improved_xe:  0.585, mse_score:  0.005)\n",
      "16:35 madminer.utils.ml.tr INFO    Early stopping after epoch 8, with loss  0.58586 compared to final loss  0.58587\n",
      "16:35 madminer.utils.ml.tr INFO    Training time spend on:\n",
      "16:35 madminer.utils.ml.tr INFO                      initialize model:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                                   ALL:   0.02h\n",
      "16:35 madminer.utils.ml.tr INFO                            check data:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                          make dataset:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                       make dataloader:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                   initialize training:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                                set lr:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                   load training batch:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                 training forward pass:   0.01h\n",
      "16:35 madminer.utils.ml.tr INFO                   training sum losses:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                         opt: backward:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                             opt: step:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                        optimizer step:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                 load validation batch:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO               validation forward pass:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                        early stopping:   0.00h\n",
      "16:35 madminer.utils.ml.tr INFO                          report epoch:   0.00h\n",
      "16:35 madminer.ml          INFO    Saving model to models/alices\n"
     ]
    }
   ],
   "source": [
    "alices = ParameterizedRatioEstimator(n_hidden=(20, 20))\n",
    "\n",
    "alices.train(\n",
    "    method=\"alices\",\n",
    "    x=\"data/x_train.npy\",\n",
    "    y=\"data/y_train.npy\",\n",
    "    theta=\"data/theta0_train.npy\",\n",
    "    r_xz=\"data/r_xz_train.npy\",\n",
    "    t_xz=\"data/t_xz_train.npy\",\n",
    "    alpha=0.1,\n",
    "    n_epochs=20,\n",
    ")\n",
    "\n",
    "alices.save(\"models/alices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try a little bit of mixing and matching -- let's train a model with CARL first and then with ALICES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:35 madminer.ml          INFO    Starting training\n",
      "16:35 madminer.ml          INFO      Method:                 carl\n",
      "16:35 madminer.ml          INFO      Batch size:             128\n",
      "16:35 madminer.ml          INFO      Optimizer:              amsgrad\n",
      "16:35 madminer.ml          INFO      Epochs:                 10\n",
      "16:35 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0003\n",
      "16:35 madminer.ml          INFO      Validation split:       0.25\n",
      "16:35 madminer.ml          INFO      Early stopping:         True\n",
      "16:35 madminer.ml          INFO      Scale inputs:           True\n",
      "16:35 madminer.ml          INFO      Scale parameters:       False\n",
      "16:35 madminer.ml          INFO      Shuffle labels          False\n",
      "16:35 madminer.ml          INFO      Samples:                all\n",
      "16:35 madminer.ml          INFO    Loading training data\n",
      "16:35 madminer.utils.vario INFO      Loading data/theta0_train.npy into RAM\n",
      "16:35 madminer.utils.vario INFO      Loading data/x_train.npy into RAM\n",
      "16:35 madminer.utils.vario INFO      Loading data/y_train.npy into RAM\n",
      "16:35 madminer.ml          INFO    Found 100000 samples with 1 parameters and 1 observables\n",
      "16:35 madminer.ml          INFO    Setting up input rescaling\n",
      "16:35 madminer.ml          INFO    Disabling parameter rescaling\n",
      "16:35 madminer.ml          INFO    Creating model\n",
      "16:35 madminer.ml          INFO    Training model\n",
      "16:35 madminer.utils.ml.tr INFO    Training on CPU with single precision\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   1: train loss  0.63071 (xe:  0.631)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.59285 (xe:  0.593)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   2: train loss  0.59224 (xe:  0.592)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.59000 (xe:  0.590)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   3: train loss  0.58987 (xe:  0.590)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58911 (xe:  0.589)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   4: train loss  0.58894 (xe:  0.589)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58959 (xe:  0.590)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   5: train loss  0.58808 (xe:  0.588)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58798 (xe:  0.588)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   6: train loss  0.58754 (xe:  0.588)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58799 (xe:  0.588)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   7: train loss  0.58724 (xe:  0.587)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58772 (xe:  0.588)\n",
      "16:35 madminer.utils.ml.tr INFO    Epoch   8: train loss  0.58680 (xe:  0.587)\n",
      "16:35 madminer.utils.ml.tr INFO               val. loss   0.58636 (xe:  0.586)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   9: train loss  0.58661 (xe:  0.587)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58635 (xe:  0.586)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch  10: train loss  0.58634 (xe:  0.586)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58645 (xe:  0.586)\n",
      "16:36 madminer.utils.ml.tr INFO    Early stopping after epoch 9, with loss  0.58635 compared to final loss  0.58645\n",
      "16:36 madminer.utils.ml.tr INFO    Training time spend on:\n",
      "16:36 madminer.utils.ml.tr INFO                      initialize model:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                                   ALL:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                            check data:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                          make dataset:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                       make dataloader:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   initialize training:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                                set lr:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   load training batch:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 training forward pass:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   training sum losses:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                         opt: backward:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                             opt: step:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        optimizer step:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 load validation batch:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO               validation forward pass:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        early stopping:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                          report epoch:   0.00h\n",
      "16:36 madminer.ml          INFO    Starting training\n",
      "16:36 madminer.ml          INFO      Method:                 alices\n",
      "16:36 madminer.ml          INFO      alpha:                  0.1\n",
      "16:36 madminer.ml          INFO      Batch size:             128\n",
      "16:36 madminer.ml          INFO      Optimizer:              amsgrad\n",
      "16:36 madminer.ml          INFO      Epochs:                 10\n",
      "16:36 madminer.ml          INFO      Learning rate:          0.0003 initially, decaying to 0.0001\n",
      "16:36 madminer.ml          INFO      Validation split:       0.25\n",
      "16:36 madminer.ml          INFO      Early stopping:         True\n",
      "16:36 madminer.ml          INFO      Scale inputs:           True\n",
      "16:36 madminer.ml          INFO      Scale parameters:       False\n",
      "16:36 madminer.ml          INFO      Shuffle labels          False\n",
      "16:36 madminer.ml          INFO      Samples:                all\n",
      "16:36 madminer.ml          INFO    Loading training data\n",
      "16:36 madminer.utils.vario INFO      Loading data/theta0_train.npy into RAM\n",
      "16:36 madminer.utils.vario INFO      Loading data/x_train.npy into RAM\n",
      "16:36 madminer.utils.vario INFO      Loading data/y_train.npy into RAM\n",
      "16:36 madminer.utils.vario INFO      Loading data/r_xz_train.npy into RAM\n",
      "16:36 madminer.utils.vario INFO      Loading data/t_xz_train.npy into RAM\n",
      "16:36 madminer.ml          INFO    Found 100000 samples with 1 parameters and 1 observables\n",
      "16:36 madminer.ml          INFO    Input rescaling already defined. To overwrite, call initialize_input_transform(x, overwrite=True).\n",
      "16:36 madminer.ml          INFO    Disabling parameter rescaling\n",
      "16:36 madminer.ml          INFO    Training model\n",
      "16:36 madminer.utils.ml.tr INFO    Training on CPU with single precision\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   1: train loss  0.58867 (improved_xe:  0.587, mse_score:  0.019)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58675 (improved_xe:  0.585, mse_score:  0.015)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   2: train loss  0.58786 (improved_xe:  0.586, mse_score:  0.015)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58619 (improved_xe:  0.585, mse_score:  0.013)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   3: train loss  0.58744 (improved_xe:  0.586, mse_score:  0.013)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58579 (improved_xe:  0.585, mse_score:  0.012)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   4: train loss  0.58717 (improved_xe:  0.586, mse_score:  0.012)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58555 (improved_xe:  0.584, mse_score:  0.011)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   5: train loss  0.58700 (improved_xe:  0.586, mse_score:  0.011)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58549 (improved_xe:  0.584, mse_score:  0.010)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   6: train loss  0.58686 (improved_xe:  0.586, mse_score:  0.010)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58529 (improved_xe:  0.584, mse_score:  0.010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:36 madminer.utils.ml.tr INFO    Epoch   7: train loss  0.58678 (improved_xe:  0.586, mse_score:  0.010)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58524 (improved_xe:  0.584, mse_score:  0.009)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   8: train loss  0.58672 (improved_xe:  0.586, mse_score:  0.009)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58483 (improved_xe:  0.584, mse_score:  0.009)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch   9: train loss  0.58665 (improved_xe:  0.586, mse_score:  0.009)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58514 (improved_xe:  0.584, mse_score:  0.009)\n",
      "16:36 madminer.utils.ml.tr INFO    Epoch  10: train loss  0.58660 (improved_xe:  0.586, mse_score:  0.009)\n",
      "16:36 madminer.utils.ml.tr INFO               val. loss   0.58501 (improved_xe:  0.584, mse_score:  0.008)\n",
      "16:36 madminer.utils.ml.tr INFO    Early stopping after epoch 8, with loss  0.58483 compared to final loss  0.58501\n",
      "16:36 madminer.utils.ml.tr INFO    Training time spend on:\n",
      "16:36 madminer.utils.ml.tr INFO                      initialize model:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                                   ALL:   0.01h\n",
      "16:36 madminer.utils.ml.tr INFO                            check data:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                          make dataset:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                       make dataloader:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                       setup optimizer:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   initialize training:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                                set lr:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   load training batch:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        fwd: move data:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   fwd: check for nans:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                    fwd: model.forward:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 fwd: calculate losses:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 training forward pass:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   training sum losses:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        opt: zero grad:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                         opt: backward:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                   opt: clip grad norm:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                             opt: step:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        optimizer step:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 load validation batch:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO               validation forward pass:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                 validation sum losses:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                        early stopping:   0.00h\n",
      "16:36 madminer.utils.ml.tr INFO                          report epoch:   0.00h\n",
      "16:36 madminer.ml          INFO    Saving model to models/mix\n"
     ]
    }
   ],
   "source": [
    "mix = ParameterizedRatioEstimator(n_hidden=(20, 20))\n",
    "\n",
    "mix.train(\n",
    "    method=\"carl\",\n",
    "    x=\"data/x_train.npy\",\n",
    "    y=\"data/y_train.npy\",\n",
    "    theta=\"data/theta0_train.npy\",\n",
    "    n_epochs=10,\n",
    "    initial_lr=0.001,\n",
    "    final_lr=0.0003,\n",
    ")\n",
    "\n",
    "mix.train(\n",
    "    method=\"alices\",\n",
    "    x=\"data/x_train.npy\",\n",
    "    y=\"data/y_train.npy\",\n",
    "    theta=\"data/theta0_train.npy\",\n",
    "    r_xz=\"data/r_xz_train.npy\",\n",
    "    t_xz=\"data/t_xz_train.npy\",\n",
    "    alpha=0.1,\n",
    "    n_epochs=10,\n",
    "    initial_lr=0.0003,\n",
    "    final_lr=0.0001,\n",
    ")\n",
    "\n",
    "mix.save(\"models/mix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now generate some test data, which is sampled corresponding to `theta=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_param_points_test = 1000  # number of parameter points to test\n",
    "theta_test = 1.0 * np.ones(shape=n_param_points_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the simulator to get observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, _, _ = simulate(theta_test)\n",
    "np.save(\"data/x_test.npy\", x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate the expected likelihood ratio on a range of parameter points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_grid = np.linspace(-5.0, 5.0, 100).reshape(-1, 1)\n",
    "np.save(\"data/theta_grid.npy\", theta_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example, we can calculate the true likelihood ratio. We will save the expected log likelihood ratio (multiplied with a conventional factor of -2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log_r_test_true = []\n",
    "nllr_test_true = []\n",
    "\n",
    "for theta in theta_grid:\n",
    "    log_r = np.log(calculate_likelihood_ratio(x_test, theta))\n",
    "    nllr_test_true.append(-2.0 * np.mean(log_r))\n",
    "    all_log_r_test_true.append(log_r)\n",
    "\n",
    "all_log_r_test_true = np.asarray(all_log_r_test_true).reshape((100, n_param_points_test))\n",
    "nllr_test_true = np.asarray(nllr_test_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to evaluate our likelihood ratio estimators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:36 madminer.ml          INFO    Loading model from models/carl\n",
      "16:36 madminer.ml          WARNING Parameter scaling information not found in models/carl\n",
      "16:36 madminer.ml          INFO    Loading evaluation data\n",
      "16:36 madminer.utils.vario INFO      Loading data/x_test.npy into RAM\n",
      "16:36 madminer.utils.vario INFO      Loading data/theta_grid.npy into RAM\n",
      "16:36 madminer.ml          INFO    Starting ratio evaluation for 100000 x-theta combinations\n",
      "16:36 madminer.ml          INFO    Evaluation done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.33694755884881883\n"
     ]
    }
   ],
   "source": [
    "carl = ParameterizedRatioEstimator()\n",
    "carl.load(\"models/carl\")\n",
    "\n",
    "log_r, _ = carl.evaluate(\n",
    "    theta=\"data/theta_grid.npy\",\n",
    "    x=\"data/x_test.npy\",\n",
    "    evaluate_score=False,\n",
    ")\n",
    "\n",
    "nllr_test_carl = -2.0 * np.mean(log_r, axis=1)\n",
    "mse_carl = np.mean((all_log_r_test_true - log_r) ** 2)\n",
    "print(\"MSE:\", mse_carl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:36 madminer.ml          INFO    Loading model from models/alices\n",
      "16:36 madminer.ml          WARNING Parameter scaling information not found in models/alices\n",
      "16:36 madminer.ml          INFO    Loading evaluation data\n",
      "16:36 madminer.utils.vario INFO      Loading data/x_test.npy into RAM\n",
      "16:36 madminer.utils.vario INFO      Loading data/theta_grid.npy into RAM\n",
      "16:36 madminer.ml          INFO    Starting ratio evaluation for 100000 x-theta combinations\n",
      "16:36 madminer.ml          INFO    Evaluation done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08978034265638975\n"
     ]
    }
   ],
   "source": [
    "alices = ParameterizedRatioEstimator()\n",
    "alices.load(\"models/alices\")\n",
    "\n",
    "log_r, _ = alices.evaluate(\n",
    "    theta=\"data/theta_grid.npy\",\n",
    "    x=\"data/x_test.npy\",\n",
    "    evaluate_score=False,\n",
    ")\n",
    "\n",
    "nllr_test_alices = -2.0 * np.mean(log_r, axis=1)\n",
    "mse_alices = np.mean((all_log_r_test_true - log_r) ** 2)\n",
    "print(\"MSE:\", mse_alices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:36 madminer.ml          INFO    Loading model from models/mix\n",
      "16:36 madminer.ml          WARNING Parameter scaling information not found in models/mix\n",
      "16:36 madminer.ml          INFO    Loading evaluation data\n",
      "16:36 madminer.utils.vario INFO      Loading data/x_test.npy into RAM\n",
      "16:36 madminer.utils.vario INFO      Loading data/theta_grid.npy into RAM\n",
      "16:36 madminer.ml          INFO    Starting ratio evaluation for 100000 x-theta combinations\n",
      "16:36 madminer.ml          INFO    Evaluation done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1589101197350935\n"
     ]
    }
   ],
   "source": [
    "mix = ParameterizedRatioEstimator()\n",
    "mix.load(\"models/mix\")\n",
    "\n",
    "log_r, _ = mix.evaluate(\n",
    "    theta=\"data/theta_grid.npy\",\n",
    "    x=\"data/x_test.npy\",\n",
    "    evaluate_score=False,\n",
    ")\n",
    "\n",
    "nllr_test_mix = -2.0 * np.mean(log_r, axis=1)\n",
    "mse_mix = np.mean((all_log_r_test_true - log_r) ** 2)\n",
    "print(\"MSE:\", mse_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the expected log likelihood ratio over parameter space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_fit_alices = float(theta_grid[np.argmin(nllr_test_alices)])\n",
    "best_fit_carl = float(theta_grid[np.argmin(nllr_test_carl)])\n",
    "best_fit_mix = float(theta_grid[np.argmin(nllr_test_mix)])\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.plot(\n",
    "    theta_grid,\n",
    "    nllr_test_true,\n",
    "    ls=\"--\",\n",
    "    c=\"black\",\n",
    "    label=r\"Ground truth ($\\theta = 1.0$)\",\n",
    ")\n",
    "plt.plot(\n",
    "    theta_grid,\n",
    "    nllr_test_carl,\n",
    "    label=r\"CARL ($\\hat{\\theta} = \" + \"{:.3f}$)\".format(best_fit_carl),\n",
    ")\n",
    "plt.plot(\n",
    "    theta_grid,\n",
    "    nllr_test_alices,\n",
    "    label=r\"ALICES ($\\hat{\\theta} = \" + \"{:.3f}$)\".format(best_fit_alices),\n",
    ")\n",
    "plt.plot(\n",
    "    theta_grid,\n",
    "    nllr_test_mix,\n",
    "    label=r\"CARL-ALICES ($\\hat{\\theta} = \" + \"{:.3f}$)\".format(best_fit_mix),\n",
    ")\n",
    "\n",
    "plt.xlabel(r\"$\\theta$\")\n",
    "plt.ylabel(r\"$\\mathbb{E}_x [ -2\\, \\log \\,r(x | \\theta, \\theta_{1}) ]$\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the new ALICES approach leads to a better approximation of the true likelihood ratio than the CARL estimate. Note that we only trained in the parameter range (-4, 4), so the deviations at the left and right of the plot are to be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madminer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
